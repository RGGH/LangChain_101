{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef300724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1946a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f97e6",
   "metadata": {},
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf9aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d279ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikipedia.run('Langchain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc9038",
   "metadata": {},
   "source": [
    "## Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fbf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c840a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395a1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python_repl.run(\"print(17*2)\")(\"print(17*2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee0d1c",
   "metadata": {},
   "source": [
    "## DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3430493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5fb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"who whon the 1990 world cup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf83bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "class DDG(DDGS):\n",
    "    def run (query:str):\n",
    "        '''\n",
    "        \"snippet\": result[\"body\"],\n",
    "        \"title\": result[\"title\"],\n",
    "        \"link\": result[\"href\"],\n",
    "        '''\n",
    "        results = DDGS().text(query)\n",
    "        generator = [result['body'] for result in results]\n",
    "\n",
    "        # Get the first three results from the generator\n",
    "        first_three_results = list(islice(generator, 3))\n",
    "        return first_three_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import OpenAI\n",
    "# llm = OpenAI(temperature=0)\n",
    "\n",
    "# This is way cheaper! \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63820da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "from typing import Dict, Optional\n",
    "\n",
    "class PythonREPL:\n",
    "    \"\"\"Simulates a standalone Python REPL.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass        \n",
    "\n",
    "    def run(self, command: str) -> str:\n",
    "        \"\"\"Run command and returns anything printed.\"\"\"\n",
    "        # sys.stderr.write(command)\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = mystdout = StringIO()\n",
    "        try:\n",
    "            exec(command, globals())\n",
    "            sys.stdout = old_stdout\n",
    "            output = mystdout.getvalue()\n",
    "        except Exception as e:\n",
    "            sys.stdout = old_stdout\n",
    "            output = str(e)\n",
    "        # sys.stderr.write(\"PYTHON OUTPUT: \\\"\" + output + \"\\\"\\n\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5eebd0",
   "metadata": {},
   "source": [
    "## Math chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00dc0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain import LLMMathChain\n",
    "\n",
    "#llm_math_chain = LLMMathChain(llm=llm, verbose=True) <- Deprecated !!!\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "math_tool = Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"Useful for when you need to answer questions about math. This tool is only for math questions and nothing else. Only input math expressions.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a4757b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Python REPL\",\n",
    "        func=PythonREPL().run,\n",
    "        description=\"useful for when you need to use python to answer a question. You should input python code\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='wikipedia',\n",
    "        func= wikipedia.run,\n",
    "        description=\"Useful for when you need to look up a topic, country or person on wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='DuckDuckGo Search',\n",
    "        func= DDG.run,\n",
    "        description=\"Useful for when you need to do a search on the internet to find information that another tool can't find. be specific with your input.\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "374daaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(math_tool) # example of adding a tool retrospectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b64f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5392ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"calculate time to drive 100 miles at 70 miles per hour, convert your answer into hours and minutes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b42395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the time it takes to drive 100 miles at a speed of 70 miles per hour. Then, I need to convert the answer into hours and minutes.\n",
      "Action: Calculator\n",
      "Action Input: 100 / 70\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "100 / 70\u001b[32;1m\u001b[1;3m```text\n",
      "100 / 70\n",
      "```\n",
      "...numexpr.evaluate(\"100 / 70\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m1.4285714285714286\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 1.4285714285714286\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the time it takes to drive 100 miles at a speed of 70 miles per hour. Now I need to convert it into hours and minutes.\n",
      "Action: Python REPL\n",
      "Action Input: 1.4285714285714286 * 60\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: It takes approximately 1 hour and 25 minutes to drive 100 miles at a speed of 70 miles per hour.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 1340\n",
      "Prompt Tokens: 1184\n",
      "Completion Tokens: 156\n",
      "Total Cost (USD): $0.002088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It takes approximately 1 hour and 25 minutes to drive 100 miles at a speed of 70 miles per hour.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = zero_shot_agent.run(query_1)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a6035",
   "metadata": {},
   "source": [
    "# Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36863f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    agent_executor_kwargs={\"handle_parsing_errors\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4863756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_04 = \"what is the 9th prime number?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccf243af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse tool input: {'name': 'python', 'arguments': 'def is_prime(n):\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\ncount = 0\\nnum = 2\\nwhile count < 9:\\n    if is_prime(num):\\n        count += 1\\n    num += 1\\n\\nnum'} because the `arguments` is not valid JSON.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Python_REPL` with `def is_prime(n):\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "count = 0\n",
      "num = 2\n",
      "while count < 9:\n",
      "    if is_prime(num):\n",
      "        count += 1\n",
      "    num += 1\n",
      "\n",
      "num`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThe 9th prime number is 23.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 1186\n",
      "Prompt Tokens: 970\n",
      "Completion Tokens: 216\n",
      "Total Cost (USD): $0.0018869999999999998\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent_executor.run({\"input\": question_04})\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4e01e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1=\"if I  will be half my dad's age next year and he is going to be 60 how old am I now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f4e4baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate my current age based on the information given.\n",
      "Action: Calculator\n",
      "Action Input: 60 - (1 + 0.5)\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "60 - (1 + 0.5)\u001b[32;1m\u001b[1;3m```text\n",
      "60 - (1 + 0.5)\n",
      "```\n",
      "...numexpr.evaluate(\"60 - (1 + 0.5)\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m58.5\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 58.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: I am currently 58.5 years old.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 869\n",
      "Prompt Tokens: 787\n",
      "Completion Tokens: 82\n",
      "Total Cost (USD): $0.0013445\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = zero_shot_agent.run(query_1)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7873df",
   "metadata": {},
   "source": [
    "# PALChain ðŸ¦œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a30a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mdef solution():\n",
      "    \"\"\"If I drive at 60 miles per hour except for the first 20 minutes of the journey from my house when I have to do 30 miles per hour, calculate how long will it take me to drive to London and return back home - London is 100 miles away. I stop for 15 minutes for petrol and a pit stop on the way back. Please answer in hours and minutes!\"\"\"\n",
      "    distance = 100  # miles\n",
      "    speed_normal = 60  # miles per hour\n",
      "    speed_slow = 30  # miles per hour\n",
      "    time_normal = distance / speed_normal  # hours\n",
      "    time_slow = 20 / 60  # hours\n",
      "    time_total = time_normal + time_slow + time_normal  # hours\n",
      "    time_total_minutes = time_total * 60  # minutes\n",
      "    time_total_minutes += 15  # add 15 minutes for the pit stop\n",
      "    hours = int(time_total_minutes // 60)\n",
      "    minutes = int(time_total_minutes % 60)\n",
      "    result = (hours, minutes)\n",
      "    return result\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 1400\n",
      "Prompt Tokens: 1175\n",
      "Completion Tokens: 225\n",
      "Total Cost (USD): $0.0022125\n",
      "\n",
      "Final Result = (3, 55)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import PALChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# This is way cheaper! \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", max_tokens=1000)\n",
    "\n",
    "# create chain\n",
    "pal_chain = PALChain.from_math_prompt(llm, verbose=True)\n",
    "\n",
    "# the question we want answered\n",
    "question_02= \"If I drive at 60 miles per hour except for\"\\\n",
    "    \"the first 20 minutes of the journey from my house\"\\\n",
    "    \"when I have to do 30 miles per hour,\"\\\n",
    "    \"calculate how long will it take me to drive to London\"\\\n",
    "    \"and return back home - London is 100 miles away\"\\\n",
    "    \"I stop for 15 minutes for petrol and a piss on the way back?\"\\\n",
    "    \"please answer in hours and minutes!\"\n",
    "\n",
    "# run the chain + check cost\n",
    "with get_openai_callback() as cb:\n",
    "    result = pal_chain({\"question\": question_02})\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
    "\n",
    "# print the answer\n",
    "res = result\n",
    "res.get('result')\n",
    "print(f\"\\nFinal Result = {res['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008ac41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
