{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef300724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66a0fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900bf768",
   "metadata": {},
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68a92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bf9aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f7f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d279ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vectors of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run('Langchain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb9ba9",
   "metadata": {},
   "source": [
    "## REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4fbf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c840a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "395a1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.run(\"print(17*2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034482a",
   "metadata": {},
   "source": [
    "## DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3430493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e95acc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who whon the 1990 world cup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acf83bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "class DDG(DDGS):\n",
    "    def run (query:str):\n",
    "        '''\n",
    "        \"snippet\": result[\"body\"],\n",
    "        \"title\": result[\"title\"],\n",
    "        \"link\": result[\"href\"],\n",
    "        '''\n",
    "        results = DDGS().text(query)\n",
    "        generator = [result['body'] for result in results]\n",
    "\n",
    "        # Get the first three results from the generator\n",
    "        first_three_results = list(islice(generator, 4))\n",
    "        return first_three_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e89562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fb6b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"python repl\",\n",
    "        func=python_repl.run,\n",
    "        description=\"useful for when you need to use python to answer a question. You should input python code\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='wikipedia',\n",
    "        func= wikipedia.run,\n",
    "        description=\"Useful for when you need to look up a topic, country or person on wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='DuckDuckGo Search',\n",
    "        func= DDG.run,\n",
    "        description=\"Useful for when you need to do a search on the internet to find information that another tool can't find. be specific with your input.\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada51fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent.run(\"When was Michael Saylor born?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
