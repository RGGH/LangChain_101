{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef300724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "263cb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1ab8c",
   "metadata": {},
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68a92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bf9aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f7f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d279ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vectors of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run('Langchain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb174de9",
   "metadata": {},
   "source": [
    "## REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4fbf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c840a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "395a1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.run(\"print(17*2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d3ffa",
   "metadata": {},
   "source": [
    "## DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3430493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d5a8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who whon the 1990 world cup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acf83bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "class DDG(DDGS):\n",
    "    def run (query:str):\n",
    "        '''\n",
    "        \"snippet\": result[\"body\"],\n",
    "        \"title\": result[\"title\"],\n",
    "        \"link\": result[\"href\"],\n",
    "        '''\n",
    "        results = DDGS().text(query)\n",
    "        generator = [result['body'] for result in results]\n",
    "\n",
    "        # Get the first three results from the generator\n",
    "        first_three_results = list(islice(generator, 4))\n",
    "        return first_three_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e89562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe12bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"python repl\",\n",
    "        func=python_repl.run,\n",
    "        description=\"useful for when you need to use python to answer a question. You should input python code\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='wikipedia',\n",
    "        func= wikipedia.run,\n",
    "        description=\"Useful for when you need to look up a topic, country or person on wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name='DuckDuckGo Search',\n",
    "        func= DDG.run,\n",
    "        description=\"Useful for when you need to do a search on the internet to find information that another tool can't find. be specific with your input.\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e41da077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3bcaec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Saylor was born.\n",
      "Action: Wikipedia\n",
      "Action Input: Michael Saylor\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out when Michael Saylor was born.\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: Michael Saylor birthdate\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m['Life Saylor was born in Lincoln, Nebraska on February 4, 1965, and spent his early years on various Air Force bases around the world, as his father was an Air Force chief master sergeant. When Saylor was 11, the family settled in Fairborn, Ohio, near the Wright-Patterson Air Force Base. [3] [4]', \"Birthdate: February 4, 1965 Age: 58 years old (as of 2023) Ethnicity: Unknown Nationality: American Sexuality: N/A Michael Saylor was born on the 4th of February, 1965. He is best known for being a Entrepreneur. Saylor and fellow business executive and educational entrepreneur Sal Khan both graduated from MIT. Michael Saylor's age is 58.\", '#1818 Billionaires (2022) Dropped off in 2023 #4 Crypto Rich List (2021) Personal Stats Age 58 Source of Wealth cryptocurrency, Self Made Residence Vienna, Virginia Citizenship United States...', \"January 1, 2021 The Accused Fraudster Behind the Bitcoin Boom MicroStrategy CEO Michael Saylor has invested billions in Bitcoin. Can we trust himâ€”or the cryptocurrency's skyrocketing value?...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Saylor was born on February 4, 1965.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Michael Saylor was born on February 4, 1965.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent.run(\"When was Michael Saylor born?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8c1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
